\documentclass[12pt]{report}

\usepackage{graphics}
\usepackage{epsfig}
\usepackage{times}
\usepackage{amsmath}
%\usepackage{natbib}
%\usepackage[style=authoryear]{biblatex}
% \addbibresource{mendely.bib} 
% <http://psl.cs.columbia.edu/phdczar/proposal.html>:
%
% The standard departmental thesis proposal format is the following:
%        30 pages
%        12 point type
%        1 inch margins all around = 6.5   inch column
%        (Total:  30 * 6.5   = 195 page-inches)
%
% For letter-size paper: 8.5 in x 11 in
% Latex Origin is 1''/1'', so measurements are relative to this.

\topmargin      0.0in
\headheight     0.0in
\headsep        0.0in
\oddsidemargin  0.0in
\evensidemargin 0.0in
\textheight     9.0in
\textwidth      6.5in

\title{{\bf A Review on Recent Advances in Unsupervised Relation Extraction} \\
\it Term Paper for Recent Advances on Semantics \\ supervised by Prof.Dr.Pinkal}
\author{ {\bf Ehsan Khoddammohammadi}  \\
Faculty of Computational Linguistics \\
Saarland University\\
{\small ehsank@coli.uni-saarland.de}
}
\date{\today}

\begin{document}
\pagestyle{plain}
\pagenumbering{roman}
\maketitle

\pagebreak
\begin{abstract}

The aim of this paper is to review recent and influential methods on
Unsupervised Relation Extraction. In the first chapter, the definition and a general background
for relation extraction task is provided which identifies important aspects and
difficulties of the task. In the second chapter, five major previous works are
briefly reviewed. The third chapter is dedicated to a weakly supervised method, distant supervision, which is 
necessary due to its impact on recent advances in the task. And
finally in the last chapter, the paper will be concluded by comparison of discussed methods and important lessons learned from each of them.

\end{abstract}

\pagebreak
\tableofcontents
\pagebreak

\cleardoublepage
\pagenumbering{arabic}

\chapter{Introduction}
\label{ch:intro}

This part provides an overall introduction of the unsupervised relation extraction task, including
definition and various formulations of the task.

\section{Definition}
\label{ch:intro}

Relation Extraction is the task of detecting and classifying semantic rela-
tionship between named entities (NE). The goal of this task is to find a triple
of binary relations and their arguments. For instance, we want to induce a
relation like \emph{bornIn} with its arguments which could be for example like this:\emph{ (
bornIn, Richard Stallman, New York )}. Applications of such task is numerous
in natural language processing; Question/Answering, machine translation and
text summarization are systems that benefit from relation extraction.

In this task, we are trying to have a model to find paraphrases which means
that we are interested to have all the similar semantically similar relations under
one umbrella. So it is desired to have all different surface realizations of one
relation like \emph{isGivenBirth, isBorn, isFrom} in a same set, namely \emph{bornIn}.

Here, in this paper, we only limit ourselves to review unsupervised relation discovery methods. 
One should mention that there are other approaches for this task based on the extent of resources that they use.
 The different category of approaches is dependent on if they heavily use annotated corpora (supervised learning) or 
 small amount of training data (weakly supervised learning). Here, in contrast, 
 We just discuss methods that do not use annotated resources for inducing the relations and finding the arguments. 



\chapter{Major Recent Works on Unsupervised Relation Extraction}
\label{ch:related}

From a classic method, DIRT, to very famous frameworks ,
TextRunner or distant supervision, and more recent works e.g. PATTY,
all are examples of several different family of approaches. These methods could
be categorized from different perspectives (1) amount of annotated data they
need (2) if they can only handle a predefined enumeration of entities and re-
lations or are open to any number of relations (3) organization of semantic
interpretation and (4) underlying family of methods they use.
he content of your proposal. Each topic occupies one section, each
with their own conclusion and future work.
In this section we will review these major works. We will discuss their formulation of the task, their models
 and the features they incorporate, the model constraints and finally we will take a look at how good a model is performing.


\section{DIRT}
\label{ch:unsupervised}

\section{TextRunner}
\label{ch:unsupervised}

\section{USP}
\label{ch:unsupervised}

In this section we will review the first unsupervised semantic parsing method which proposed by Poon and Domingos ???,
we will first define what is semantic parsing and after describing the method in ??? we show its application for relation extraction.
In the evaluation subsection we will compare this model to its related models and analyze its advantages and disadvantages.

\subsection{Semantic Parsing}
\label{ch:definition}

Semantic parsing is mapping a sentence to its formal meaning represntation ???%cite{PoonDomingos2009}
The aim is to represent a natural language text with first-order logic. One can derive a semantic parse of a sentence
by starting from a lexicon of atomic formulas and combining each fragment to build a composition of 
formulas combined with quantifiers and logical connectives. In ???%cite{PoonDomingos2009} 
 the lexicon will be induced from a raw corpus. It is in contrast to traditional means of semantic parsing with manually
  produced lexicons.
  
  The main challange in unsupervised semantic parsing is that for a single semantic representation there could be
  several syntactic realizations or even harder, different surface representations. For example, all of the
   sentences below has a same semantic representation:
   \begin{itemize}
     \item Microsoft buys Skype
     \item Microsoft acquires the VoIP company Skype
     \item Skype is acquired by Microsoft Corporation
     \item The Redmond software giant buys Skype
     \item Microsoftâ€™s purchase of Skype,\ldots
   \end{itemize}  
  
   A simple lexicon to represent all of the examples above is:
  
   $$ BUY(n_1)$$
   $$ \lambda x_2.BUYER(n_1 , x_2) \; \;  \lambda x_3.BOUGHT(n_1 , x_3) $$
   $$ MICROSOFT(n_2) \; \; SKYPE(n_3)$$
   
   Having a corpus of sentences in natural language, USP %???\cite{domingosPoon}
    will induce such a lexicon and will also extract a formal representation for each sentence. In the next 
    subsection we will review the necessary steps toward this goal.
\subsection{Model Description}
\label{ch:model}


\subsection {Evaluation}
\label{ch:evaluation}
sdgdsg

\section{Rel-LDA \& Type-LDA}
\label{ch:unsupervised}

In this section we will review the method proposed for relation discovery  by Yao et. al. 
The method they  proposed is an unsupervised method using generative models which is based on 
modification of well-known model, Latent Dirichlet Allocation. 
They have invented three similar models which we will go through them in following. 
We elaborate on input of the three models and then we describe their generative story 
and at the end we will finish this part by discussing about  model evaluation.

\subsection{Input format and preprocessing}
\label{ch:input}
Authors have chosen a subset of New York Times articles from year 2000 to 2007 which some of its parts with
abnormal style of writing like obituary content are filtered out.
They have done several pre-processing steps:
\begin{enumerate}
\item Tokenization
\item Sentence split
\item POS tagging (?? all last three steps with Stanford tools)
\item Named entity tagging ( ?? Finkel2005)
\item Dependency parsing (??MaltParser)
\end{enumerate}
Among all dependency paths they are just interested in those which link two named entities.
 Authors assume that realization of one relation is available in this 
 path most likely as a verb which relates two mentioned named entities. These types of 
 paths are collected and based on some conditions that we have already discussed in (??? DIRT), non-important links are filtered out.
 
 As an example ???
 Finally in this phase, 2.5 million dependency paths were collected 
 which will serve as an input to the models that we describe in the next subsection.


\subsection {Model Description}
\label{ch:model}
All the three models in this work are generative models. Generative models are jointly modeling hidden variables and observable variables and 
are in contrast to discriminative models. For more information on generative models please see ?? and ??.\\


\textbf{Rel-LDA} is the first model proposed in (?? Yao). 
In this model, features, $f$, are generated from a distribution , $\Phi_{rf}$. Each type
 of relation is represented with a binary indicator variable, $r$. Each document is a mixture of few relations
  and relations are generated from a multinomial distribution $\Theta_{doc}$. $\Theta_{doc}$ is a distribution
  of relations for a specific document and can be shown as $P(r|doc)$. By choosing a right prior distribution for $\Theta$
   and $\Phi$ we can impose an assumption that any document contains a few number of relation types. 
   Another advantage of having prior is that it helps to avoid overfitting. Dirichlet prior with small parameter $\alpha$ is 
   chosen for this purpose in the paper. For more on the role of priors and specially Dirichlet prior
    please read ?? and ??.
    Rel-LDA is decribed with a graphical model in figure ???.
    Shaded circles are showing the observable variables and other circles are hidden variables except 
    the priors which are set by ourselves. The direction of arrow shows the dependency in this sense 
    that destination node (variable) is dependent on source node.
      
    Features or observable variables in Rel-LDA are:
    \begin{itemize}
      \item The dependency path
      \item Source of the path (the first named entity)
      \item Destination of the path (the second named entity)
    \end{itemize}
   	
   	An exact sampling method called \emph{variational inference} is used by authors to compute 
   	the posterior distribution of the model, $P(r|f)$.
   	After learning, we will have clusters of relation types which each instance of a specific cluster 
   	is a relation that is supposed to be semantically equivalent to the other members of this cluster.
   	\\
   	
   	In the second model, \textbf{Rel-LDA1},The only difference is that  more features are used in the learning procedure.
   	 The idea is that using more features could be useful as tie-breakers and also discriminators between instances
   	  to make new clusters. With direct reference to the paper, the authors believe that more features 
   	  lead to better refinement of clusters. We will see later that this assumption holds in practice.
   	   The new features that they have introduced in this new model are:
   	   \begin{itemize}
   	     \item Trigger: Any word in a dependency path except than stop words. 
   	     \item Part of speech sequence: The sequence of pos tags of a dependency path. 
   	     \item Named entity pair: The type of source and destination named entity.
   	     \item Syntactic pair: The type of dependency edges connecting source and destination to the head.
   	   \end{itemize}   
   
 Among all the newly introduced features, NE pair is the most interesting one which leads to a 
 significant observation that the third model will try to address that. Authors observed that 
 Rel-LDA will put these three relations in one cluster because the second argument of all of them is location:
 
 \begin{enumerate}
   \item \emph{ X was born in Y}
   \item \emph{ X lives in Y}
   \item \emph{ X, a company in Y}
 \end{enumerate}
 
 While the first argument in the first two relations refers to a PER, the first argument of the 
 third relation is an instance of ORG type. By using NER pairs as feature we can split this cluster 
 to two clusters with respect to basic types of NE in relations arguments. 
 This observation leads us to invest more on type identification of arguments to have more pure 
 clusters and is the main focus of the third model, \textbf{Type-LDA}.
 
 
 Selectional preferences of a relation are constraint over possible arguments for the relation.
  Basically, any relation only accepts a few number of entity types and this could be an important constraint
   for inducing relations. Relations of each cluster should have similar selectional preferences and
    accept same entity types. Type-LDA is proposed for this reason, it will induce entity types 
    and relation clusters jointly to benefit more from selectional preferences of relations.
    
    The generative model is modified in a way that features of arguments (source and destination)
    will be generated from two new distributions, $T_1$ \& $T_2$ which are modeling entity types. The graphical model
    is shown in fig ???. This model not only clusters relations but also clusters entities to entity clusters.
    
    For their experiments on all three models they have set the number of relation clusters to 100 and for Type-LDA they used 
     50 entity clusters. Choosing other numbers of relation clusters in the range of 50 to 200 is shown to be not very significant.
    
\subsection {Evaluation}
\label{ch:evaluation}

Yao et al. have evaluated their models in different settings. Their comparison against Mintz et al.?? previous work
 will be mentioned in the next chapter which is dedicated to distant supervision. They have used human judgments 
 to measure their models precision. Humans are asked to label 50 instances in each relation cluster and in order to measure
 the recall, induced relations are compared against Freebase. Table ?? shows the results.
 
 ???
 
 Like most of the other models, antonymy is not handled in their model and therefor for example they have
 \emph{X was born in Y} and \emph{X die in Y} in one cluster.
 
 Entity clusters also sometimes suffer from high-frequency or low-frequency words and for example, `New York`
 , is in the same cluster as other publications like `New York Times`, `Vanity Fair` and \ldots
 
 Yao et al. have shown that they have induced relations in different granularity from Freebase and reported some relations
 which are not mentioned in Freebase but positively hold. For example, Freebase relation \emph{worksFor}
  is subsumed with more relations each indicates a different role of employment relation. \emph{leaderOf}
   and \emph{editorOf} are such examples. This will boost the idea of inducing heirarchical 
   relations which will be discussed more in the last chapter.
 
 

\chapter{Weakly Supervised on Relation Extraction Task}
\label{ch:related}

\section{Distant Supervision}
\label{ch:weakly supervised}

The content of \cite{Huang2012} your proposal. Each topic occupies one section, each
with their own conclusion and future work.

\chapter{Conclusion}
\label{ch:conclusion}

\section{Analysis}
\label{ch:conclusion}

Based on what we have seen in recent works, we can now give a list of vital
attributes that a state-of-the-art model for extracting relations from open text
should be able to carry out. The author will use these facts to suggest a list of possible improvements
in the next section. Modeling all of
these factors in a joint model is the necessary step to push forward the previous
works.

\begin{description}
  
  \item[The number of relations and entities is an unknown parameter.] \hfill \\
  The model can not be confined to a limited set of relations or entities. Being able to extract relations in
  open domain text is the first and (most likely) a trivial attribute of the model. More non-trivial feature
  of the model should be its ability to extract as many relations as there are in text. 
  Giving this freedom
  about the model complexity to have no assumption about the exact number of entities and relations
  is suggested by the applicant to be beneficial 
   and is also supported in the literature.
   %\citep{Yates2007}\citep{Mintz2009} 

  \item[Relations may not be expressed explicitly in text.] \hfill \\
  Relation extraction task is definitely more than finding paraphrases. The model should be able to handle
  long-distance relations among entities as well as hidden semantic indications of a relation.
  
  %\citep{PoonDomingos2009} 

  \item[Relations and entities have their inner organization and types.] \hfill \\
  It is shown by several recent works that relations of relations play a substantial role in identifying
  relations. Relations and entities belong to a hierarchy of types and therefore the constraints they put on each other
  should be learnt as well.
  %\citep{Yao2011}\citep{Alfonesca2012}\citep{NakasholeWeikum2012}

  \item[Using KB is necessary but not enough.] \hfill \\
  There are more relations among entities than what is collected in 
  Knowledge Bases e.g. Freebase. At the same time, it is statistically shown that a supervision
  from such resources strongly contributes to convergance of any model to a better 
  objective configurations.
  %\citep{Mintz2009}\citep{Bordes2011}\citep{Yao2011}

  \item[Relations and entities are sharing information within each other.] \hfill \\
  Relations and entities should be learnt jointly since they share same explanatory factors (hidden variables)
  . Meaning of a entity can be learnt from its relation to other entities and same argument holds among relations.
  Basically, the model should be able to carry multi-task learning. 
  %\citep{Yao2011}\citep{Bordes2011}
    
\end{description}


\section{Summary}
\label{ch:conclusion}


Provide an overview of what you have done and what need to be done.

%\subsection{Plan for completion of the research}

%Table \ref{tab:plan} shows my plan for completion of the research.

%\begin{table}[hc]
%\begin{small}
%\begin{center}
%\begin{tabular}{lll}
%Timeline & Work & Progress\\
%\hline
%          & XXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX & completed\\
%Nov. xxxx & XXXXXXXXXXXXXXXXXXXXXXXXXXX & ongoing\\
%Jan. xxxx & Thesis writting & \\
%Feb. xxxx & Thesis defense & \\
%\end{tabular}
%\end{center}
%\end{small}
%\caption{Plan for completion of my research}
%\label{tab:plan}
%\end{table}



\pagebreak

\begin{footnotesize}
\bibliographystyle{plain}
%\bibliographystyle{agsm}
\bibliography{mendely.bib}
%\printbibliography
\end{footnotesize}

\end{document}


